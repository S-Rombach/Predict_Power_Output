{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Predict the power production using sunshine duration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Init, Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from src.config import DATA_RAW_DIR, POWER_OPENMETEO_WEATHER_FILENAME\n",
    "from src.transformation import prepare_aggregate_openmeteo_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv(\n",
    "    os.path.join(DATA_RAW_DIR, POWER_OPENMETEO_WEATHER_FILENAME),\n",
    "    sep=\";\",\n",
    "    usecols=[\n",
    "        \"installation\",\n",
    "        \"timestamp\",\n",
    "        \"sol_prod\",\n",
    "        \"cloud_cover\",\n",
    "        \"snow_depth\",\n",
    "        \"sunshine_duration\",\n",
    "        \"is_day\",\n",
    "        \"direct_radiation\",\n",
    "        \"weather_description\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_doy = prepare_aggregate_openmeteo_data(df_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_doy[\"sol_prod\"]\n",
    "X = df_doy.reset_index().drop([\"sol_prod\"], axis=1)\n",
    "\n",
    "# last year as holdout\n",
    "split_point = len(X) - 365\n",
    "X_train, X_test = X.loc[:split_point], X.loc[split_point + 1 :]\n",
    "y_train, y_test = y.loc[:split_point], y.loc[split_point + 1 :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import Ridge\n",
    "from src.transformers import DayOfYearTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ohe.columns can be interpreted as numeric, because they represent the share of a certain weather type on the whole day\n",
    "num_cols = [c for c in sum_cols + mean_cols + list(ohe.columns) if c != \"sol_prod\"]\n",
    "\n",
    "num_pipe = Pipeline(\n",
    "    steps=[\n",
    "        (\"scale\", MinMaxScaler()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "doy_sin_pipe = Pipeline(\n",
    "    steps=[\n",
    "        (\"trig\", DayOfYearTransformer(\"sin\")),\n",
    "    ]\n",
    ")\n",
    "doy_cos_pipe = Pipeline(\n",
    "    steps=[\n",
    "        (\"trig\", DayOfYearTransformer(\"cos\")),\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", num_pipe, num_cols),\n",
    "        (\"sin\", doy_sin_pipe, [\"date\"]),\n",
    "        (\"cos\", doy_cos_pipe, [\"date\"]),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    ")\n",
    "preprocessor.set_output(transform=\"pandas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "### Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = Ridge(alpha=1.0)\n",
    "model = Pipeline(steps=[(\"prep\", preprocessor), (\"reg\", reg)])\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model_evaluation.regressor_evaluation import evaluate_regressor\n",
    "from datetime import datetime\n",
    "\n",
    "results = evaluate_regressor(\n",
    "    regressor=reg,\n",
    "    y_true=y_test,\n",
    "    y_pred=y_pred,\n",
    "    timestamp=datetime.now(),\n",
    "    model_purpose=\"predict\",\n",
    "    special_features=\"mult-weather,feateng-doytrig\",\n",
    ")\n",
    "\n",
    "print(\"Evaluation Results:\")\n",
    "for key in [\n",
    "    k\n",
    "    for k in [\"MAE\", \"MSE\", \"RMSE\", \"MAPE\", \"MedAE\", \"R2\", \"ExplainedVar\"]\n",
    "    if k in results\n",
    "]:\n",
    "    print(f\"  {key}: {results.get(key):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "## Save Model And Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import json\n",
    "import os\n",
    "\n",
    "from src.config import MODELS_DIR\n",
    "\n",
    "model_name = results[\"model_name\"]\n",
    "\n",
    "folder = os.path.join(MODELS_DIR, model_name)\n",
    "filename = os.path.join(folder, model_name)\n",
    "os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "# because of issues with pickling custom transformers,\n",
    "# save only the config and results\n",
    "\n",
    "with open(f\"{filename}.model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(reg, f)\n",
    "\n",
    "with open(f\"{filename}.pipeline.pkl\", \"wb\") as f:\n",
    "    pickle.dump(preprocessor, f)\n",
    "\n",
    "with open(f\"{filename}.model.txt\", \"w\") as file:\n",
    "    file.write(str(reg))\n",
    "\n",
    "with open(f\"{filename}.model_params.json\", \"w\") as f:\n",
    "    json.dump(reg.get_params(), f, indent=2)\n",
    "\n",
    "with open(f\"{filename}.pipeline_params.txt\", \"w\") as f:\n",
    "    f.write(preprocessor.get_params().__str__())\n",
    "\n",
    "with open(f\"{filename}.results.json\", \"w\") as f:\n",
    "    json.dump(results, f, indent=2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "predict-power-output",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

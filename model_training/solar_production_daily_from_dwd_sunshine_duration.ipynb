{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Predict the power production using sunshine duration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Init, Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from src.config import DATA_RAW_DIR, POWER_DWD_WEATHER_FILENAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv(\n",
    "    os.path.join(DATA_RAW_DIR, POWER_DWD_WEATHER_FILENAME),\n",
    "    sep=\";\",\n",
    "    usecols=[\n",
    "        \"installation\",\n",
    "        \"timestamp\",\n",
    "        \"sol_prod\",\n",
    "        \"sunshine_duration\",\n",
    "        \"radiation_global\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw[\"date\"] = pd.to_datetime(df_raw[\"timestamp\"]).dt.tz_convert(None).dt.normalize()\n",
    "\n",
    "df_doy = (\n",
    "    df_raw.groupby([\"installation\", \"date\"])\n",
    "    .agg({\"sunshine_duration\": \"sum\", \"radiation_global\": \"sum\", \"sol_prod\": \"sum\"})\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "df_doy = df_doy.sort_values([\"date\"])\n",
    "\n",
    "df_doy = df_doy.drop([\"installation\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_doy[\"sol_prod\"]\n",
    "X = df_doy.reset_index().drop([\"sol_prod\"], axis=1)\n",
    "\n",
    "# last year as holdout\n",
    "split_point = len(X) - 365\n",
    "X_train, X_test = X.loc[:split_point], X.loc[split_point + 1 :]\n",
    "y_train, y_test = y.loc[:split_point], y.loc[split_point + 1 :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "\n",
    "def day_of_year_trig_transformer(trig_function):\n",
    "    \"\"\"\n",
    "    Create a FunctionTransformer that applies a trigonometric transformation (sin or cos)\n",
    "    to the day of year extracted from a datetime column or DataFrame.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    trig_function : str\n",
    "        The trigonometric function to use, either \"sin\" or \"cos\".\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    FunctionTransformer\n",
    "        A scikit-learn FunctionTransformer that transforms datetime features into their\n",
    "        corresponding trigonometric representation of the day of year.\n",
    "\n",
    "    Example\n",
    "    -------\n",
    "    >>> transformer = day_of_year_trig_transformer(\"sin\")\n",
    "    >>> transformer.transform(pd.DataFrame({\"date\": pd.to_datetime([\"2022-01-01\", \"2022-06-30\"])}))\n",
    "    array([[ 0.01721421],\n",
    "           [ 0.9998477 ]])\n",
    "    \"\"\"\n",
    "\n",
    "    def _feature_names_out(self, input_features=None):\n",
    "        if input_features is None:\n",
    "            return np.array([f\"doy_{trig_function}\"])\n",
    "        return np.array([f\"{c}_doy_{trig_function}\" for c in input_features])\n",
    "\n",
    "    def _extract_dayofyear(x):\n",
    "        if isinstance(x, pd.Series) and np.issubdtype(x.dtype, np.datetime64):\n",
    "            return x.dt.dayofyear.to_frame()\n",
    "        elif isinstance(x, pd.DataFrame):\n",
    "            x = x.copy()\n",
    "            for col in x.columns:\n",
    "                x[col] = x[col].dt.dayofyear\n",
    "            return x\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"Input must be a pandas Series with datetime64 dtype\"\n",
    "                \" or a DataFrame with datetime64 columns.\"\n",
    "            )\n",
    "\n",
    "    def _extract_days_in_year(x):\n",
    "        if isinstance(x, pd.Series) and np.issubdtype(x.dtype, np.datetime64):\n",
    "            return x.dt.is_leap_year.map({True: 366, False: 365}).to_frame()\n",
    "        elif isinstance(x, pd.DataFrame):\n",
    "            x = x.copy()\n",
    "            for col in x.columns:\n",
    "                x[col] = x[col].dt.is_leap_year.map({True: 366, False: 365})\n",
    "            return x\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"Input must be a pandas Series with datetime64 dtype\"\n",
    "                \" or a DataFrame with datetime64 columns.\"\n",
    "            )\n",
    "\n",
    "    def _trig_transformer(x):\n",
    "        # Use a defined function to make the transformer pickable\n",
    "        if trig_function == \"sin\":\n",
    "            return np.sin(_extract_dayofyear(x) / _extract_days_in_year(x) * 2 * np.pi)\n",
    "        elif trig_function == \"cos\":\n",
    "            return np.cos(_extract_dayofyear(x) / _extract_days_in_year(x) * 2 * np.pi)\n",
    "        else:\n",
    "            raise ValueError(\"trig_function must be 'sin' or 'cos'\")\n",
    "\n",
    "    return FunctionTransformer(_trig_transformer, feature_names_out=_feature_names_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = [\"sunshine_duration\"]\n",
    "\n",
    "num_pipe = Pipeline(\n",
    "    steps=[\n",
    "        (\"scale\", MinMaxScaler()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "doy_sin_pipe = Pipeline(\n",
    "    steps=[\n",
    "        (\"trig\", day_of_year_trig_transformer(\"sin\")),\n",
    "    ]\n",
    ")\n",
    "doy_cos_pipe = Pipeline(\n",
    "    steps=[\n",
    "        (\"trig\", day_of_year_trig_transformer(\"cos\")),\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", num_pipe, num_cols),\n",
    "        (\"sin\", doy_sin_pipe, [\"date\"]),\n",
    "        (\"cos\", doy_cos_pipe, [\"date\"]),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    ")\n",
    "preprocessor.set_output(transform=\"pandas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "### Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = Ridge(alpha=1.0)\n",
    "model = Pipeline(steps=[(\"prep\", preprocessor), (\"reg\", reg)])\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model_evaluation.regressor_evaluation import evaluate_regressor\n",
    "from datetime import datetime\n",
    "\n",
    "results = evaluate_regressor(\n",
    "    regressor=reg,\n",
    "    y_true=y_test,\n",
    "    y_pred=y_pred,\n",
    "    timestamp=datetime.now(),\n",
    "    model_purpose=\"predict\",\n",
    "    special_features=\"sunshine,feateng-doytrig\",\n",
    ")\n",
    "\n",
    "print(\"Evaluation Results:\")\n",
    "for key in [\n",
    "    k\n",
    "    for k in [\"MAE\", \"MSE\", \"RMSE\", \"MAPE\", \"MedAE\", \"R2\", \"ExplainedVar\"]\n",
    "    if k in results\n",
    "]:\n",
    "    print(f\"  {key}: {results.get(key):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "## Save Model And Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import json\n",
    "import os\n",
    "\n",
    "from src.config import MODELS_DIR\n",
    "\n",
    "model_name = results[\"model_name\"]\n",
    "\n",
    "folder = os.path.join(MODELS_DIR, model_name)\n",
    "filename = os.path.join(folder, model_name)\n",
    "os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "# because of issues with pickling custom transformers,\n",
    "# saving only config and results\n",
    "\n",
    "# with open(f\"{filename}.model.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(reg, f)\n",
    "\n",
    "# with open(f\"{filename}.pipeline.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(preprocessor, f)\n",
    "\n",
    "with open(f\"{filename}.model.txt\", \"w\") as file:\n",
    "    file.write(str(reg))\n",
    "\n",
    "with open(f\"{filename}.model_params.json\", \"w\") as f:\n",
    "    json.dump(reg.get_params(), f, indent=2)\n",
    "\n",
    "with open(f\"{filename}.pipeline_params.txt\", \"w\") as f:\n",
    "    f.write(preprocessor.get_params().__str__())\n",
    "\n",
    "with open(f\"{filename}.results.json\", \"w\") as f:\n",
    "    json.dump(results, f, indent=2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "predict-power-output",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

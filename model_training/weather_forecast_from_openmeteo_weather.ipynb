{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Create a model to predict the weather next year using trigonometric features and lags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Init, Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from src.config import DATA_RAW_DIR, OPENMETEO_WEATHER_FILENAME\n",
    "from src.transformation import prepare_aggregate_openmeteo_data\n",
    "\n",
    "MAX_LAG_DAYS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv(\n",
    "    os.path.join(DATA_RAW_DIR, OPENMETEO_WEATHER_FILENAME),\n",
    "    sep=\";\",\n",
    "    index_col=[\"timestamp\"],\n",
    ")\n",
    "\n",
    "display(df_raw.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg = prepare_aggregate_openmeteo_data(\n",
    "    df_raw.reset_index(),\n",
    "    weather_column=\"weather_description\",\n",
    "    mandatory_weather_columns=[\n",
    "        \"clear_sky\",\n",
    "        \"cloudy\",\n",
    "        \"drizzle\",\n",
    "        \"rain\",\n",
    "        \"solid_precipitation\",\n",
    "    ],\n",
    ")\n",
    "display(df_agg.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Train, Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# last year as holdout\n",
    "split_point = len(df_agg) - 365 - MAX_LAG_DAYS\n",
    "\n",
    "Xy_train, Xy_test = df_agg.loc[:split_point], df_agg.loc[split_point + MAX_LAG_DAYS + 1 :]\n",
    "\n",
    "display(Xy_train.tail(5))\n",
    "display(Xy_test.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_columns = [\n",
    "    \"sunshine_duration\",\n",
    "    \"direct_radiation\",\n",
    "    \"cloud_cover\",\n",
    "    \"snow_depth\",\n",
    "    \"is_day\",\n",
    "    \"clear_sky\",\n",
    "    \"cloudy\",\n",
    "    \"drizzle\",\n",
    "    \"rain\",\n",
    "    \"solid_precipitation\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import Ridge\n",
    "from src.transformers import DayOfYearTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "### Add Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "#### Lag Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.transformers import LagFeatureTransformer\n",
    "\n",
    "lft = LagFeatureTransformer(lags=list(range(1, MAX_LAG_DAYS + 1)))\n",
    "lft.set_output(transform=\"pandas\")\n",
    "\n",
    "X_train = pd.concat(\n",
    "    [\n",
    "        Xy_train[[\"date\"]],\n",
    "        lft.fit_transform(Xy_train[target_columns], y=None),\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "y_train = pd.concat([Xy_train[[\"date\"]], Xy_train[target_columns]], axis=1)\n",
    "\n",
    "X_test = pd.concat(\n",
    "    [\n",
    "        Xy_test[[\"date\"]],\n",
    "        lft.transform(Xy_test[target_columns]),\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "y_test = pd.concat([Xy_test[[\"date\"]], Xy_test[target_columns]], axis=1)\n",
    "\n",
    "display(X_train.head(5))\n",
    "display(y_train.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "#### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ohe.columns can be interpreted as numeric, because they represent the share of a certain weather type on the whole day\n",
    "\n",
    "num_cols = [\n",
    "    c\n",
    "    for c in X_test.columns\n",
    "    if c not in [\"sol_prod\", \"date\"]\n",
    "]\n",
    "\n",
    "num_pipe = Pipeline(\n",
    "    steps=[\n",
    "        (\"scale\", MinMaxScaler()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "doy_sin_pipe = Pipeline(\n",
    "    steps=[\n",
    "        (\"trig\", DayOfYearTransformer(\"sin\")),\n",
    "    ]\n",
    ")\n",
    "doy_cos_pipe = Pipeline(\n",
    "    steps=[\n",
    "        (\"trig\", DayOfYearTransformer(\"cos\")),\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", num_pipe, num_cols),\n",
    "        (\"sin\", doy_sin_pipe, [\"date\"]),\n",
    "        (\"cos\", doy_cos_pipe, [\"date\"]),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    ")\n",
    "preprocessor.set_output(transform=\"pandas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train = Xy_train.drop(target_columns, axis=1)\n",
    "y_train = Xy_train[target_columns]\n",
    "X_test = Xy_test.drop(target_columns, axis=1)\n",
    "y_test = Xy_test[target_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model_evaluation.regressor_evaluation import evaluate_regressor\n",
    "from datetime import datetime\n",
    "\n",
    "results = evaluate_regressor(\n",
    "    regressor=regressor,\n",
    "    y_true=y_test,\n",
    "    y_pred=y_pred,\n",
    "    timestamp=datetime.now(),\n",
    "    model_purpose=\"feat-eng\",\n",
    "    special_features=\"trig-doy\",\n",
    ")\n",
    "\n",
    "print(\"Evaluation Results:\")\n",
    "for key in [\n",
    "    k\n",
    "    for k in [\"MAE\", \"MSE\", \"RMSE\", \"MAPE\", \"MedAE\", \"R2\", \"ExplainedVar\"]\n",
    "    if k in results\n",
    "]:\n",
    "    print(f\"  {key}: {results.get(key):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "## Save Model And Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "import json\n",
    "import os\n",
    "\n",
    "from src.config import MODELS_DIR\n",
    "\n",
    "model_name = results[\"model_name\"]\n",
    "\n",
    "folder = os.path.join(MODELS_DIR, model_name)\n",
    "filename = os.path.join(folder, model_name)\n",
    "os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "# because of issues with pickling custom transformers,\n",
    "# saving only config and results\n",
    "\n",
    "# with open(f\"{filename}.model.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(reg, f)\n",
    "\n",
    "# with open(f\"{filename}.pipeline.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(preprocessor, f)\n",
    "\n",
    "with open(f\"{filename}.model.txt\", \"w\") as file:\n",
    "    file.write(str(regressor))\n",
    "\n",
    "with open(f\"{filename}.model_params.json\", \"w\") as f:\n",
    "    json.dump(regressor.get_params(), f, indent=2)\n",
    "\n",
    "with open(f\"{filename}.pipeline_params.txt\", \"w\") as f:\n",
    "    f.write(preprocessor.get_params().__str__())\n",
    "\n",
    "with open(f\"{filename}.results.json\", \"w\") as f:\n",
    "    json.dump(results, f, indent=2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "predict-power-output",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Create a model for total solar production using trigonometric features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Init, Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from src.config import DATA_RAW_DIR, DATA_RAW_FILENAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv(\n",
    "    os.path.join(DATA_RAW_DIR, DATA_RAW_FILENAME),\n",
    "    sep=\";\",\n",
    "    index_col=[\"timestamp\"],\n",
    "    date_format=\"%Y-%m-%d %H:%M\",\n",
    ")\n",
    "# Recover data in relevant columns\n",
    "df_raw.loc[df_raw[\"sol_prod\"].isna(), \"sol_prod\"] = (\n",
    "    df_raw[df_raw[\"sol_prod\"].isna()][\"sol_prod_1\"]\n",
    "    + df_raw[df_raw[\"sol_prod\"].isna()][\"sol_prod_2\"]\n",
    ")\n",
    "\n",
    "df_raw = df_raw.reset_index()\n",
    "\n",
    "display(df_raw.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sum = df_raw.copy().reset_index()\n",
    "df_sum[\"date\"] = pd.to_datetime(df_sum[\"timestamp\"]).dt.normalize()\n",
    "\n",
    "df_sum = df_sum[[\"date\", \"sol_prod\"]].groupby([\"date\"]).sum()\n",
    "df_sum = df_sum.reset_index().sort_values(by=\"date\", ascending=True)\n",
    "display(df_sum.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Train, Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_sum[[\"date\"]], df_sum[\"sol_prod\"], test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "### Transformer\n",
    "Idea from [scikit-learn](https://scikit-learn.org/stable/auto_examples/applications/plot_cyclical_feature_engineering.html#data-exploration-on-the-bike-sharing-demand-dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "\n",
    "def sin_transformer(period):\n",
    "    \"\"\"Create a sine transformer.\n",
    "\n",
    "    Args:\n",
    "        period (int): The period of the sine wave.\n",
    "    \"\"\"\n",
    "\n",
    "    def get_feature_names(self, x):\n",
    "        return [f\"{y}_sin\" for y in x]\n",
    "\n",
    "    def _sin_transformer(x):\n",
    "        # Use a defined function to make the transformer pickable\n",
    "        return np.sin(x / period * 2 * np.pi)\n",
    "\n",
    "    return FunctionTransformer(_sin_transformer, feature_names_out=get_feature_names)\n",
    "\n",
    "\n",
    "def cos_transformer(period):\n",
    "    \"\"\"Create a cosine transformer.\n",
    "\n",
    "    Args:\n",
    "        period (int): The period of the cosine wave.\n",
    "    \"\"\"\n",
    "\n",
    "    def get_feature_names(self, x):\n",
    "        return [f\"{y}_cos\" for y in x]\n",
    "\n",
    "    def _cos_transformer(x):\n",
    "        # Use a defined function to make the transformer pickable\n",
    "        return np.cos(x / period * 2 * np.pi)\n",
    "\n",
    "    return FunctionTransformer(_cos_transformer, feature_names_out=get_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dayofyear_extractor():\n",
    "    \"\"\"Create a day of year extractor transformer.\"\"\"\n",
    "\n",
    "    def get_feature_names(self, x):\n",
    "        return [f\"{y}_dayofyear\" for y in x]\n",
    "\n",
    "    def extract_dayofyear(x):\n",
    "        if isinstance(x, pd.Series) and np.issubdtype(x.dtype, np.datetime64):\n",
    "            return x.dt.dayofyear\n",
    "        elif isinstance(x, pd.DataFrame):\n",
    "            x = x.copy()\n",
    "            for col in x.columns:\n",
    "                x[col] = x[col].dt.dayofyear\n",
    "            return x\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"Input must be a pandas Series with datetime64 dtype\"\n",
    "                \" or a DataFrame with datetime64 columns.\"\n",
    "            )\n",
    "\n",
    "    return FunctionTransformer(extract_dayofyear, feature_names_out=get_feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "### Add Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "dayofyear_sin_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"extract_dayofyear\", dayofyear_extractor()),\n",
    "        (\"transform_sin\", sin_transformer(366)),\n",
    "    ]\n",
    ")\n",
    "dayofyear_cos_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"extract_dayofyear\", dayofyear_extractor()),\n",
    "        (\"transform_cos\", cos_transformer(366)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"dayofyear\", dayofyear_extractor(), [\"date\"]),\n",
    "        (\"sin\", dayofyear_sin_pipeline, [\"date\"]),\n",
    "        (\"cos\", dayofyear_cos_pipeline, [\"date\"]),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    ")\n",
    "preprocessor.set_output(transform=\"pandas\")\n",
    "\n",
    "regressor = RidgeCV()\n",
    "pipe = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"model\", regressor)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model_evaluation.regressor_evaluation import evaluate_regressor\n",
    "from datetime import datetime\n",
    "\n",
    "results = evaluate_regressor(\n",
    "    regressor=regressor,\n",
    "    y_true=y_test,\n",
    "    y_pred=y_pred,\n",
    "    timestamp=datetime.now(),\n",
    "    model_purpose=\"feat-eng\",\n",
    "    special_features=\"trig-doy\",\n",
    ")\n",
    "\n",
    "print(\"Evaluation Results:\")\n",
    "for key in [\n",
    "    k\n",
    "    for k in [\"MAE\", \"MSE\", \"RMSE\", \"MAPE\", \"MedAE\", \"R2\", \"ExplainedVar\"]\n",
    "    if k in results\n",
    "]:\n",
    "    print(f\"  {key}: {results.get(key):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "## Save Model And Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "import json\n",
    "import os\n",
    "\n",
    "from src.config import SOLAR_PROD_DAILY_MODELS_DIR as MODELS_DIR\n",
    "\n",
    "model_name = results[\"model_name\"]\n",
    "\n",
    "folder = os.path.join(MODELS_DIR, model_name)\n",
    "filename = os.path.join(folder, model_name)\n",
    "os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "# because of issues with pickling custom transformers,\n",
    "# saving only config and results\n",
    "\n",
    "# with open(f\"{filename}.model.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(reg, f)\n",
    "\n",
    "# with open(f\"{filename}.pipeline.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(preprocessor, f)\n",
    "\n",
    "with open(f\"{filename}.model.txt\", \"w\") as file:\n",
    "    file.write(str(regressor))\n",
    "\n",
    "with open(f\"{filename}.model_params.json\", \"w\") as f:\n",
    "    json.dump(regressor.get_params(), f, indent=2)\n",
    "\n",
    "with open(f\"{filename}.pipeline_params.txt\", \"w\") as f:\n",
    "    f.write(preprocessor.get_params().__str__())\n",
    "\n",
    "with open(f\"{filename}.results.json\", \"w\") as f:\n",
    "    json.dump(results, f, indent=2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "predict-power-output",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
